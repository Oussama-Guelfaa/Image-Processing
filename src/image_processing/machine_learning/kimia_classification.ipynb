{
    "cells": [{
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Image Classification with Kimia Database\n",
                "\n",
                "**Author:** Oussama GUELFAA  \n",
                "**Date:** 01-04-2025\n",
                "\n",
                "This notebook demonstrates image classification using the Kimia database. We'll extract features from binary images and use machine learning techniques to classify them."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 38.1. Feature Extraction\n",
                "\n",
                "The image database used in this tutorial is composed of 18 classes. Each class contains 12 images. All these 216 images come from the Kimia database. In order to classify these images, we first have to extract some features of each binary image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import glob\n",
                "import os\n",
                "from skimage import measure, io\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the dataset path and classes\n",
                "import glob\n",
                "# Use the correct path to the Kimia dataset\n",
                "rep = '../../data/images_Kimia/'\n",
                "classes = ['bone', 'apple', 'camel']  # We only have these 3 classes in our dataset\n",
                "    \n",
                "# If you have the full Kimia216 dataset, uncomment these classes:\n",
                "# classes = ['bird', 'bone', 'brick', 'camel', 'car', 'children',\n",
                "#           'classic', 'elephant', 'face', 'fork', 'fountain',\n",
                "#           'glass', 'hammer', 'heart', 'key', 'misk', 'ray', 'turtle']\n",
                "\n",
                "nbClasses = len(classes)\n",
                "nbImages = 20  # Each class has 20 images in our dataset\n",
                "\n",
                "# The features are manually computed\n",
                "properties = np.zeros((nbClasses*nbImages, 9))\n",
                "target = np.zeros(nbClasses * nbImages)\n",
                "index = 0\n",
                "\n",
                "for ind_c, c in enumerate(classes):\n",
                "    filelist = glob.glob(rep+c+'*')\n",
                "    for filename in filelist:\n",
                "        print(filename)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Feature Extraction Function\n",
                "\n",
                "For each image in the database, we'll extract a number of different features using scikit-image's `regionprops` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_features(image_path):\n",
                "    \"\"\"Extract region properties from a binary image.\"\"\"\n",
                "    # Read the image\n",
                "    img = io.imread(image_path, as_gray=True)\n",
                "    \n",
                "    # Ensure binary image\n",
                "    if img.max() > 1:\n",
                "        img = img > 128\n",
                "    \n",
                "    # Extract region properties\n",
                "    props = measure.regionprops(measure.label(img))[0]\n",
                "    \n",
                "    # Extract features\n",
                "    features = np.array([\n",
                "        props.area,                      # Area of the region\n",
                "        props.perimeter,                 # Perimeter of the region\n",
                "        props.eccentricity,              # Eccentricity of the region\n",
                "        props.equivalent_diameter_area,  # Diameter of circle with same area\n",
                "        props.euler_number,              # Euler number\n",
                "        props.extent,                    # Ratio of pixels in region to pixels in bounding box\n",
                "        props.major_axis_length,         # Length of major axis\n",
                "        props.minor_axis_length,         # Length of minor axis\n",
                "        props.solidity                   # Ratio of pixels in the region to pixels in the convex hull\n",
                "    ])\n",
                "    \n",
                "    return features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract features for all images\n",
                "properties = np.zeros((nbClasses*nbImages, 9))\n",
                "target = np.zeros(nbClasses * nbImages)\n",
                "index = 0\n",
                "\n",
                "for ind_c, c in enumerate(classes):\n",
                "    filelist = glob.glob(rep+c+'*')\n",
                "    for filename in filelist:\n",
                "        try:\n",
                "            # Extract features\n",
                "            features = extract_features(filename)\n",
                "            properties[index] = features\n",
                "            target[index] = ind_c\n",
                "            index += 1\n",
                "        except Exception as e:\n",
                "            print(f\"Error processing {filename}: {e}\")\n",
                "\n",
                "# Check the shape of our feature array\n",
                "print(f\"Feature array shape: {properties.shape}\")\n",
                "print(f\"Target array shape: {target.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 38.2. Image Classification\n",
                "\n",
                "In order to classify the images, we are going to use neural networks. Pattern recognition networks are feedforward networks that can be trained to classify inputs according to target classes. The inputs are the features of each image. The target data are the labels, indicating the class of each image."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 38.2.1. Construction of the Array of Properties\n",
                "\n",
                "- Build the target data, representing the class of each image. The target data for pattern recognition networks should consist of one vector containing the index of the target class. In our example, the target data will be a vector of 216 elements.\n",
                "- The database will be divided into a training set (75%) and a test set (25%)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split the data into training and test sets\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    properties, target, test_size=0.25, random_state=42, stratify=target)\n",
                "\n",
                "print(f\"Training set: {X_train.shape[0]} samples\")\n",
                "print(f\"Test set: {X_test.shape[0]} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 38.2.2. Training and Classification\n",
                "\n",
                "- Run the training task and classify the test images.\n",
                "- Show the classification confusion matrix as well as the overall performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Normalize the data\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train a neural network classifier\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "\n",
                "# Create and train the classifier\n",
                "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', \n",
                "                    solver='adam', max_iter=1000, random_state=42)\n",
                "mlp.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Make predictions\n",
                "y_pred = mlp.predict(X_test_scaled)\n",
                "\n",
                "# Calculate accuracy\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "print(f\"Accuracy: {accuracy:.2f}\")\n",
                "\n",
                "# Print classification report\n",
                "print(\"\\nClassification Report:\")\n",
                "# Convert numeric labels to string labels for the report\n",
                "class_labels = [str(i) for i in range(len(classes))]\n",
                "print(classification_report(y_test, y_pred, target_names=class_labels))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "# Use class_labels for the confusion matrix visualization\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('True')\n",
                "plt.title(f'Confusion Matrix (Accuracy: {accuracy:.2f})')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Try with SVM Classifier\n",
                "\n",
                "Let's also try using an SVM classifier to compare performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train an SVM classifier\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "# Create and train the classifier\n",
                "svm = SVC(C=1.0, kernel='rbf', gamma='scale', random_state=42)\n",
                "svm.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Make predictions\n",
                "y_pred_svm = svm.predict(X_test_scaled)\n",
                "\n",
                "# Calculate accuracy\n",
                "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
                "print(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n",
                "\n",
                "# Print classification report\n",
                "print(\"\\nSVM Classification Report:\")\n",
                "# Use the same class labels as before\n",
                "print(classification_report(y_test, y_pred_svm, target_names=class_labels))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot SVM confusion matrix\n",
                "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "# Use class_labels for the confusion matrix visualization\n",
                "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('True')\n",
                "plt.title(f'SVM Confusion Matrix (Accuracy: {accuracy_svm:.2f})')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Improving Classification Performance\n",
                "\n",
                "Let's try to change the parameters of the neural network to improve the classification performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Try a more complex neural network\n",
                "mlp_improved = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', \n",
                "                            solver='adam', max_iter=2000, alpha=0.0001,\n",
                "                            learning_rate='adaptive', random_state=42)\n",
                "mlp_improved.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Make predictions\n",
                "y_pred_improved = mlp_improved.predict(X_test_scaled)\n",
                "\n",
                "# Calculate accuracy\n",
                "accuracy_improved = accuracy_score(y_test, y_pred_improved)\n",
                "print(f\"Improved MLP Accuracy: {accuracy_improved:.2f}\")\n",
                "\n",
                "# Print classification report\n",
                "print(\"\\nImproved MLP Classification Report:\")\n",
                "# Use the same class labels as before\n",
                "print(classification_report(y_test, y_pred_improved, target_names=class_labels))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot improved MLP confusion matrix\n",
                "cm_improved = confusion_matrix(y_test, y_pred_improved)\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "# Use class_labels for the confusion matrix visualization\n",
                "sns.heatmap(cm_improved, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('True')\n",
                "plt.title(f'Improved MLP Confusion Matrix (Accuracy: {accuracy_improved:.2f})')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "In this notebook, we've demonstrated how to:\n",
                "\n",
                "1. Extract meaningful features from binary images using region properties\n",
                "2. Organize these features into a dataset suitable for machine learning\n",
                "3. Train different classifiers (MLP and SVM) on the dataset\n",
                "4. Evaluate the performance of the classifiers\n",
                "5. Improve the classification performance by tuning parameters\n",
                "\n",
                "The results show that both neural networks and SVMs can effectively classify the Kimia database images based on the extracted features."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}